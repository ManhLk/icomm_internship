{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('liu', '888', 'bin', 'liu', '888', 'bin')\n",
      "{'one': 1, 'two': 2}\n",
      "dict_values([1, 2])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from pyvi import ViTokenizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "import str\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(object):\n",
    "    \n",
    "    def load_raw_data(self, filename, is_train=True):\n",
    "        ID = []\n",
    "        label = []\n",
    "        sentence = []\n",
    "        review = ''        \n",
    "        if is_train:\n",
    "            with open(filename, 'r', encoding='utf-8') as file:\n",
    "                for line in file:\n",
    "                    if line.startswith('train_'):\n",
    "                        ID.append(line.replace('\\n',''))\n",
    "                    elif line[:-1].isdigit():\n",
    "                        review = review.replace('\\n',' ')\n",
    "                        review = ' '.join((review.lower()).split())\n",
    "                        sentence.append(review)\n",
    "                        review = ''\n",
    "                        label.append(int(line[:-1]))\n",
    "                    else:\n",
    "                        review = review +' '+ line\n",
    "        else:\n",
    "            with open(filename, 'r', encoding='utf-8') as file:\n",
    "                for line in file:\n",
    "                    if line.startswith('test_'):\n",
    "                        review = review.replace('\\n',' ')\n",
    "                        review = ' '.join((review.lower()).split())\n",
    "                        sentence.append(review)\n",
    "                        review = ''\n",
    "                        ID.append(line.replace('\\n',''))\n",
    "                    else:\n",
    "                        review = review +' '+ line\n",
    "            review = review.replace('\\n',' ')\n",
    "            review = re.sub('['+string.punctuation+']', ' ', review)\n",
    "            review = ' '.join((review.lower()).split())\n",
    "            sentence.append(review)\n",
    "            del sentence[0]\n",
    "        return (ID, label, sentence)\n",
    "    \n",
    "    def pre_processing(self, text):\n",
    "        \n",
    "        # Xoa icon linh tinh\n",
    "        emoji_pattern = re.compile(\"[\"\n",
    "                       u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                       u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                       u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                       u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                       u\"\\U00002702-\\U000027B0\"\n",
    "                       u\"\\U000024C2-\\U0001F251\"\n",
    "                       u\"\\U0001f926-\\U0001f937\"\n",
    "                       u\"\\u200d\"\n",
    "                       u\"\\u2640-\\u2642\" \n",
    "                       \"]+\", flags=re.UNICODE)\n",
    "        text = emoji_pattern.sub(r'', text)\n",
    "        \n",
    "        # Chuan hoa tieng viet, tieng anh, thuat ngu\n",
    "        replace_list={\n",
    "            'òa': 'oà', 'óa': 'oá', 'ỏa': 'oả', 'õa': 'oã', 'ọa': 'oạ', 'òe': 'oè', 'óe': 'oé','ỏe': 'oẻ',\n",
    "        'õe': 'oẽ', 'ọe': 'oẹ', 'ùy': 'uỳ', 'úy': 'uý', 'ủy': 'uỷ', 'ũy': 'uỹ','ụy': 'uỵ', 'uả': 'ủa',\n",
    "        'ả': 'ả', 'ố': 'ố', 'u´': 'ố','ỗ': 'ỗ', 'ồ': 'ồ', 'ổ': 'ổ', 'ấ': 'ấ', 'ẫ': 'ẫ', 'ẩ': 'ẩ',\n",
    "        'ầ': 'ầ', 'ỏ': 'ỏ', 'ề': 'ề','ễ': 'ễ', 'ắ': 'ắ', 'ủ': 'ủ', 'ế': 'ế', 'ở': 'ở', 'ỉ': 'ỉ',\n",
    "        'ẻ': 'ẻ', 'àk': u' à ','aˋ': 'à', 'iˋ': 'ì', 'ă´': 'ắ','ử': 'ử', 'e˜': 'ẽ', 'y˜': 'ỹ', 'a´': 'á',\n",
    "        #Chuẩn hóa 1 số sentiment words/English words\n",
    "        ':))': '  positive ', ':)': ' positive ', 'ô kêi': ' ok ', 'okie': ' ok ', ' o kê ': ' ok ',\n",
    "        'okey': ' ok ', 'ôkê': ' ok ', 'oki': ' ok ', ' oke ':  ' ok ',' okay':' ok ','okê':' ok ',\n",
    "        ' tks ': u' cám ơn ', 'thks': u' cám ơn ', 'thanks': u' cám ơn ', 'ths': u' cám ơn ', 'thank': u' cám ơn ', 'cam on':u'cám ơn',u'cảm ơn':'cám ơn',\n",
    "        'kg ': u' không ','not': u' không ', u' kg ': u' không ', '\"k ': u' không ',' kh ':u' không ','kô':u' không ','hok':u' không ',' kp ': u' không phải ',u' kô ': u' không ', '\"ko ': u' không ', u' ko ': u' không ', u' k ': u' không ', 'khong': u' không ', u' hok ': u' không ','k ':u' không ',\n",
    "        'he he': ' positive ','hehe': ' positive ','hihi': ' positive ', 'haha': ' positive ', 'hjhj': ' positive ',\n",
    "        ' lol ': ' negative ',' cc ': ' negative ','cute': u' dễ thương ','huhu': ' negative ', ' vs ': u' với ', 'wa': ' quá ', 'wá': u' quá', 'j': u' gì ', '“': ' ',\n",
    "        ' sz ': u' cỡ ', 'size': u' cỡ ', u' đx ': u' được ', 'dk': u' được ', 'dc': u' được ', 'đk': u' được ',\n",
    "        'đc': u' được ','authentic': u' chuẩn chính hãng ',u' aut ': u' chuẩn chính hãng ', u' auth ': u' chuẩn chính hãng ', 'thick': u' positive ', 'store': u' cửa hàng ',\n",
    "        'shop': u' cửa hàng ', 'sp': u' sản phẩm ', 'gud': u' tốt ','god': u' tốt ','wel done':' tốt ', 'good': u' tốt ', 'gút': u' tốt ',\n",
    "        'sấu': u' xấu ','gut': u' tốt ', u' tot ': u' tốt ', u' nice ': u' tốt ', 'perfect': 'rất tốt', 'bt': u' bình thường ',\n",
    "        'time': u' thời gian ', 'qá': u' quá ', u' ship ': u' giao hàng ', u' m ': u' mình ', u' mik ': u' mình ',\n",
    "        'ể': 'ể', 'product': 'sản phẩm', 'quality': 'chất lượng','chat':' chất ', 'excelent': 'hoàn hảo', 'bad': 'tệ','fresh': ' tươi ','sad': ' tệ ',\n",
    "        'date': u' hạn sử dụng ', 'hsd': u' hạn sử dụng ','quickly': u' nhanh ', 'quick': u' nhanh ','fast': u' nhanh ','delivery': u' giao hàng ',u' síp ': u' giao hàng ',\n",
    "        'beautiful': u' đẹp tuyệt vời ', u' tl ': u' trả lời ', u' r ': u' rồi ', u' shopE ': u' cửa hàng ',u' order ': u' đặt hàng ',\n",
    "        'chất lg': u' chất lượng ',u' sd ': u' sử dụng ',u' dt ': u' điện thoại ',u' nt ': u' nhắn tin ',u' tl ': u' trả lời ',u' sài ': u' xài ',u'bjo':u' bao giờ ',\n",
    "        'thik': u' thích ',u' sop ': u' cửa hàng ', ' fb ': ' facebook ', ' face ': ' facebook ', ' very ': u' rất ',u'quả ng ':u' quảng  ',\n",
    "        'dep': u' đẹp ',u' xau ': u' xấu ','delicious': u' ngon ', u'hàg': u' hàng ', u'qủa': u' quả ', \n",
    "        'iu': u' yêu ','fake': u' giả mạo ', 'trl': 'trả lời', '><': u' positive ', \n",
    "        ' por ': u' tệ ',' poor ': u' tệ ', 'ib':u' nhắn tin ', 'rep':u' trả lời ',u'fback':' feedback ','fedback':' feedback ',\n",
    "        'qc':u'quảng cáo',u'éo':'negative',\n",
    "        #dưới 3* quy về 1*, trên 3* quy về 5*\n",
    "        '6 sao': ' 5star ','6 star': ' 5star ', '5star': ' 5star ','5 sao': ' 5star ','5sao': ' 5star ',\n",
    "        'starstarstarstarstar': ' 5star ', '1 sao': ' 1star ', '1sao': ' 1star ','2 sao':' 1star ','2sao':' 1star ',\n",
    "        '2 starstar':' 1star ','1star': ' 1star ', '0 sao': ' 1star ', '0star': ' 1star ','1*':' 1star ', '2*':' 1star ','3*':' 5star ','4*':' 5star ','5*':' 5star '\n",
    "        }\n",
    "        for k, v in replace_list.items():\n",
    "            text = text.replace(k, v)\n",
    "        \n",
    "        #Xóa dấu câu linh tinh\n",
    "        text = re.sub('['+string.punctuation+']', ' ', text)\n",
    "        \n",
    "        # Tokenizer\n",
    "        text = ViTokenizer.tokenize(text)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    \n",
    "    def load_data(self, filename, is_train=True):\n",
    "        ID, Label, Sentence = self.load_raw_data(filename, is_train)\n",
    "        for i in range(len(Sentence)):\n",
    "            Sentence[i] = self.pre_processing(Sentence[i])\n",
    "        dic = {'0':['5star', 'positive'], '1':['1star', 'negative']}\n",
    "        for key, vals in dic.items():\n",
    "            for val in vals:\n",
    "                ID.append((len(ID)+1))\n",
    "                Label.append(key)\n",
    "                Sentence.append(val)\n",
    "        return ID, Label, Sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesModel(object):\n",
    "    def __init__(self):\n",
    "        self.clf = self._init_pipeline()\n",
    "    \n",
    "    @staticmethod\n",
    "    def _init_pipeline():\n",
    "        stopwords=('rằng', 'thì', 'mà', 'là', 'thế', 'à', 'ừ', 'vậy', 'như')\n",
    "        pipe_line = Pipeline([\n",
    "            (\"vectorizer\", CountVectorizer(stop_words=stopwords)), # bag of words\n",
    "            (\"tfidf\", TfidfTransformer()), # tf-idf\n",
    "            (\"clf\", MultinomialNB()) # navie bayes models\n",
    "        ])\n",
    "        return pipe_line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine - kernel = 'linear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVMModel(object):\n",
    "    def __init__(self):\n",
    "        self.clf = self._init_pipeline()\n",
    "        \n",
    "    @staticmethod\n",
    "    def _init_pipeline():\n",
    "        stopwords=('rằng', 'thì', 'mà', 'là', 'thế', 'à', 'ừ', 'vậy', 'như')\n",
    "        pipe_line = Pipeline([\n",
    "            (\"vectorizer\", CountVectorizer(stop_words=stopwords)), # bag of words\n",
    "            (\"tfidf\", TfidfTransformer()), # tf-idf\n",
    "            (\"clf_svm\", SVC(kernel='linear')) # svm kernel = 'linear'\n",
    "        ])\n",
    "        return pipe_line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID, Label, Sentence = Data().load_data(r'D:\\Documents\\Đồ án 2\\Sentiment Analysis\\Sentiment data\\vibo\\train.crash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame([ID, Label, Sentence]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns = ['ID', 'Label', 'Sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_000000</td>\n",
       "      <td>0</td>\n",
       "      <td>dung được sản_phẩm tốt cám_ơn cửa_hàng đóng_gó...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_000001</td>\n",
       "      <td>0</td>\n",
       "      <td>chất_lượng sản_phẩm tuyệt_vời son mịn nhưng kh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_000002</td>\n",
       "      <td>0</td>\n",
       "      <td>chất_lượng sản_phẩm tuyệt_vời nhưng không có h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_000003</td>\n",
       "      <td>1</td>\n",
       "      <td>mình hơi thất_vọng 1 chút vì mình đã kỳ_vọng c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_000004</td>\n",
       "      <td>1</td>\n",
       "      <td>lần trước mình mua áo_gió màu hồng rất o không...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>train_000005</td>\n",
       "      <td>0</td>\n",
       "      <td>chất_lượng sản_phẩm tuyệt_vời có_điều không cứ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>train_000006</td>\n",
       "      <td>0</td>\n",
       "      <td>đã nhận được hàng rất nhanh mới đặt buổi tối m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>train_000007</td>\n",
       "      <td>1</td>\n",
       "      <td>các siêu phẩm thấy cấu_hình toàn tựa tựa nhau ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>train_000008</td>\n",
       "      <td>0</td>\n",
       "      <td>hàng giao hàng nhanh chất_lượng tốt tư_vấn nhi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>train_000009</td>\n",
       "      <td>1</td>\n",
       "      <td>đồng_hồ đẹp nhưng 1 cái đứt dây 1 cái không ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>train_000010</td>\n",
       "      <td>0</td>\n",
       "      <td>chất_lượng sản_phẩm tuyệt_vời y hình chụp đáng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>train_000011</td>\n",
       "      <td>0</td>\n",
       "      <td>positive cửa_hàng giao hàng nhanh quá đẹp lắm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>train_000012</td>\n",
       "      <td>0</td>\n",
       "      <td>nhìn đẹp phết nhỉ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>train_000013</td>\n",
       "      <td>0</td>\n",
       "      <td>đóng_gói rất đẹp chất_lượng sản_phẩm rất tốt c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>train_000014</td>\n",
       "      <td>0</td>\n",
       "      <td>săn được với giá 11k toẹt vời</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>train_000015</td>\n",
       "      <td>0</td>\n",
       "      <td>o không rất hài_lòng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>train_000016</td>\n",
       "      <td>1</td>\n",
       "      <td>giao thiếu mình cái này rồi cửa_hàng ơi t_t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>train_000017</td>\n",
       "      <td>0</td>\n",
       "      <td>chất_lượng sản_phẩm tuyệt_vời tôi rất thích</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>train_000018</td>\n",
       "      <td>0</td>\n",
       "      <td>giày đẹp lắm có điều dây hơi ngắn tí ạ chất_lư...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>train_000019</td>\n",
       "      <td>0</td>\n",
       "      <td>yếm vải đẹp nhưng ít mẫu đẹp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>train_000020</td>\n",
       "      <td>0</td>\n",
       "      <td>chất_lượng sản_phẩm tuyệt_vời đóng_gói sản_phẩ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>train_000021</td>\n",
       "      <td>1</td>\n",
       "      <td>không hài_lòng sản_phẩm cho lắm giặt lan đầu_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>train_000022</td>\n",
       "      <td>0</td>\n",
       "      <td>giao hàng nhanh mặc đẹp cám_ơn cửa_hàng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>train_000023</td>\n",
       "      <td>0</td>\n",
       "      <td>chất_lượng sản_phẩm tuyệt_vời bao_bì dễ_thương...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>train_000024</td>\n",
       "      <td>1</td>\n",
       "      <td>đồng_hồ thì đẹp thật nhưng tại_sao kim lúc chạ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>train_000025</td>\n",
       "      <td>0</td>\n",
       "      <td>giao hàng siêu nhanh đóng_gói cẩn_thận và tư_v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>train_000026</td>\n",
       "      <td>1</td>\n",
       "      <td>cũng hơi bất_tiện xu_thế này e rằng đa phằn ng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>train_000027</td>\n",
       "      <td>1</td>\n",
       "      <td>toàn hàng trungkhi mua quên không coi kĩ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>train_000028</td>\n",
       "      <td>0</td>\n",
       "      <td>đóng_gói sản_phẩm rất đẹp và chắc_chắn được cử...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>train_000029</td>\n",
       "      <td>0</td>\n",
       "      <td>hôm_nay chiên thử cá_hồi cá_chiên ăn ngọt hơn ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID Label                                           Sentence\n",
       "0   train_000000     0  dung được sản_phẩm tốt cám_ơn cửa_hàng đóng_gó...\n",
       "1   train_000001     0  chất_lượng sản_phẩm tuyệt_vời son mịn nhưng kh...\n",
       "2   train_000002     0  chất_lượng sản_phẩm tuyệt_vời nhưng không có h...\n",
       "3   train_000003     1  mình hơi thất_vọng 1 chút vì mình đã kỳ_vọng c...\n",
       "4   train_000004     1  lần trước mình mua áo_gió màu hồng rất o không...\n",
       "5   train_000005     0  chất_lượng sản_phẩm tuyệt_vời có_điều không cứ...\n",
       "6   train_000006     0  đã nhận được hàng rất nhanh mới đặt buổi tối m...\n",
       "7   train_000007     1  các siêu phẩm thấy cấu_hình toàn tựa tựa nhau ...\n",
       "8   train_000008     0  hàng giao hàng nhanh chất_lượng tốt tư_vấn nhi...\n",
       "9   train_000009     1  đồng_hồ đẹp nhưng 1 cái đứt dây 1 cái không ch...\n",
       "10  train_000010     0  chất_lượng sản_phẩm tuyệt_vời y hình chụp đáng...\n",
       "11  train_000011     0  positive cửa_hàng giao hàng nhanh quá đẹp lắm ...\n",
       "12  train_000012     0                                  nhìn đẹp phết nhỉ\n",
       "13  train_000013     0  đóng_gói rất đẹp chất_lượng sản_phẩm rất tốt c...\n",
       "14  train_000014     0                      săn được với giá 11k toẹt vời\n",
       "15  train_000015     0                               o không rất hài_lòng\n",
       "16  train_000016     1        giao thiếu mình cái này rồi cửa_hàng ơi t_t\n",
       "17  train_000017     0        chất_lượng sản_phẩm tuyệt_vời tôi rất thích\n",
       "18  train_000018     0  giày đẹp lắm có điều dây hơi ngắn tí ạ chất_lư...\n",
       "19  train_000019     0                       yếm vải đẹp nhưng ít mẫu đẹp\n",
       "20  train_000020     0  chất_lượng sản_phẩm tuyệt_vời đóng_gói sản_phẩ...\n",
       "21  train_000021     1  không hài_lòng sản_phẩm cho lắm giặt lan đầu_t...\n",
       "22  train_000022     0            giao hàng nhanh mặc đẹp cám_ơn cửa_hàng\n",
       "23  train_000023     0  chất_lượng sản_phẩm tuyệt_vời bao_bì dễ_thương...\n",
       "24  train_000024     1  đồng_hồ thì đẹp thật nhưng tại_sao kim lúc chạ...\n",
       "25  train_000025     0  giao hàng siêu nhanh đóng_gói cẩn_thận và tư_v...\n",
       "26  train_000026     1  cũng hơi bất_tiện xu_thế này e rằng đa phằn ng...\n",
       "27  train_000027     1           toàn hàng trungkhi mua quên không coi kĩ\n",
       "28  train_000028     0  đóng_gói sản_phẩm rất đẹp và chắc_chắn được cử...\n",
       "29  train_000029     0  hôm_nay chiên thử cá_hồi cá_chiên ăn ngọt hơn ..."
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16091 entries, 0 to 16090\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   ID        16091 non-null  object\n",
      " 1   Label     16091 non-null  object\n",
      " 2   Sentence  16091 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 377.3+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train_df.loc[:,'Sentence'].values, (train_df.loc[:,'Label'].values).astype('int'), test_size = .2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8980733374766936\n",
      "Test accuracy: 0.8657968313140727\n"
     ]
    }
   ],
   "source": [
    "model = NaiveBayesModel()\n",
    "clf = model.clf.fit(x_train, y_train)\n",
    "print(\"Train accuracy:\",clf.score(x_train, y_train))\n",
    "print(\"Test accuracy:\", clf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM kernel = 'linear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9377719080174021\n",
      "Test accuracy: 0.8800869835352594\n"
     ]
    }
   ],
   "source": [
    "clf_svm = SVMModel().clf.fit(x_train, y_train)\n",
    "print(\"Train accuracy:\",clf_svm.score(x_train, y_train))\n",
    "print(\"Test accuracy:\", clf_svm.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input from keyboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mời bạn nhập bình luận: amazing goot chop em\n",
      "tích cực\n"
     ]
    }
   ],
   "source": [
    "sentiment = ['tích cực', 'tiêu cực']\n",
    "test_data = {}\n",
    "test_data['Sentence']= input('Mời bạn nhập bình luận: ')\n",
    "test_df = pd.DataFrame(test_data,index=[0])\n",
    "predict = clf_svm.predict(test_df['Sentence'])[0]\n",
    "print(sentiment[predict])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter error label predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = clf_svm.predict(train_df['Sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_predict_df = train_df[train_df['Label']!= predict_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\manhlk\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "length = []\n",
    "for i in range(error_predict_df.shape[0]):\n",
    "    length.append(len((error_predict_df['Sentence'][error_predict_df.index[i]]).split()))\n",
    "error_predict_df['Length_sentence'] = length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Length_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15958</th>\n",
       "      <td>train_015958</td>\n",
       "      <td>0</td>\n",
       "      <td>vì không đúng mẫu và màu_da nên không_thể đánh...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15961</th>\n",
       "      <td>train_015961</td>\n",
       "      <td>0</td>\n",
       "      <td>sản_phẩm rất o không</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15963</th>\n",
       "      <td>train_015963</td>\n",
       "      <td>1</td>\n",
       "      <td>quạt đẹp giá tốt rất hài_lòng với sản pham</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15976</th>\n",
       "      <td>train_015976</td>\n",
       "      <td>0</td>\n",
       "      <td>hồi đó mình xài s5 nhưng chạy theo phong_trào ...</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15993</th>\n",
       "      <td>train_015993</td>\n",
       "      <td>0</td>\n",
       "      <td>như l</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16029</th>\n",
       "      <td>train_016029</td>\n",
       "      <td>0</td>\n",
       "      <td>rất ấn_tượng</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16087</th>\n",
       "      <td>16088</td>\n",
       "      <td>0</td>\n",
       "      <td>5star</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16088</th>\n",
       "      <td>16089</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16089</th>\n",
       "      <td>16090</td>\n",
       "      <td>1</td>\n",
       "      <td>1star</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16090</th>\n",
       "      <td>16091</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID Label                                           Sentence  \\\n",
       "15958  train_015958     0  vì không đúng mẫu và màu_da nên không_thể đánh...   \n",
       "15961  train_015961     0                               sản_phẩm rất o không   \n",
       "15963  train_015963     1         quạt đẹp giá tốt rất hài_lòng với sản pham   \n",
       "15976  train_015976     0  hồi đó mình xài s5 nhưng chạy theo phong_trào ...   \n",
       "15993  train_015993     0                                              như l   \n",
       "16029  train_016029     0                                       rất ấn_tượng   \n",
       "16087         16088     0                                              5star   \n",
       "16088         16089     0                                           positive   \n",
       "16089         16090     1                                              1star   \n",
       "16090         16091     1                                           negative   \n",
       "\n",
       "       Length_sentence  \n",
       "15958               10  \n",
       "15961                4  \n",
       "15963                9  \n",
       "15976               92  \n",
       "15993                2  \n",
       "16029                2  \n",
       "16087                1  \n",
       "16088                1  \n",
       "16089                1  \n",
       "16090                1  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_predict_df[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_predict_data = pd.ExcelWriter('error_predict.xlsx',engine='xlsxwriter')\n",
    "error_predict_df.to_excel(false_predict_data,sheet_name='Sheet1')\n",
    "false_predict_data.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1191.000000\n",
       "mean       15.477750\n",
       "std        14.857111\n",
       "min         0.000000\n",
       "25%         6.000000\n",
       "50%        11.000000\n",
       "75%        20.000000\n",
       "max       153.000000\n",
       "Name: Length_sentence, dtype: float64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_predict_df['Length_sentence'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
